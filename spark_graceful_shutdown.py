from pyspark.sql import SparkSession
from pyspark.sql.functions import col, from_json, count
from pyspark.sql.types import StructType, StructField, StringType, TimestampType
import signal
import sys
import time

class GracefulShutdown:
    def __init__(self, query):
        self.query = query
        self.shutdown_requested = False
        
        signal.signal(signal.SIGINT, self.request_shutdown)
        signal.signal(signal.SIGTERM, self.request_shutdown)
    
    def request_shutdown(self, signum, frame):
        print("\nüõë Shutdown requested - initiating graceful shutdown...")
        print("   1. Finishing current batch...")
        print("   2. Committing offsets...")
        print("   3. Closing connections...")
        
        self.shutdown_requested = True
        
        self.query.stop()
        
        print("‚úÖ Graceful shutdown complete")
        print("üíæ State saved - can resume from last committed offset")
        sys.exit(0)

spark = SparkSession.builder \
    .appName("GracefulShutdown") \
    .master("local[*]") \
    .config("spark.jars.packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0") \
    .config("spark.sql.streaming.checkpointLocation", "/tmp/spark-checkpoints-recovery") \
    .getOrCreate()

spark.sparkContext.setLogLevel("WARN")

print("üîÑ GRACEFUL SHUTDOWN DEMO")
print("üìä Goal: Deploy updates without data loss")
print("üëî Use Case: Rolling deployment during business hours")
print("-" * 70)

schema = StructType([
    StructField("event_id", StringType()),
    StructField("user_id", StringType()),
    StructField("event_type", StringType()),
    StructField("timestamp", TimestampType()),
])

df = spark.readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", "localhost:9092") \
    .option("subscribe", "user_clicks") \
    .option("startingOffsets", "latest") \
    .load()

df = df.selectExpr("CAST(value AS STRING)") \
    .select(from_json(col("value"), schema).alias("data")).select("data.*")

result = df.groupBy("event_type").count()

query = result.writeStream \
    .outputMode("complete") \
    .format("console") \
    .option("truncate", False) \
    .trigger(processingTime='10 seconds') \
    .start()

shutdown_handler = GracefulShutdown(query)

print("\nüõ°Ô∏è  GRACEFUL SHUTDOWN ENABLED:")
print("   - Press Ctrl+C to trigger graceful shutdown")
print("   - Current batch will complete before stopping")
print("   - Offsets committed to checkpoint")
print("   - On restart: Resume from last committed offset")
print("\nüíº BUSINESS BENEFIT:")
print("   - Deploy updates during business hours")
print("   - Zero data loss during deployment")
print("   - Downtime: ~5 seconds (batch completion time)")
print("\nüöÄ Running...\n")

query.awaitTermination()
